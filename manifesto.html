---
layout: default
title: The Critical AI Manifesto
permalink: /manifesto
css: manifesto
image: /images/cail_banner.png
description: "On this page are some resources for Critical AI Literacy (CAIL) from my perspective."
published: false

---


<article class="page">



<div class="row">
  <div class="col-12">
<ul class="socials">
   <li class="social">
    <a href="{{site.url}}">
      <i class="fa-solid fa-home"></i></a>
    </li>
    <li class="social">
    <a href="#here">
      <i class="fa-solid fa-moon" id="dark" onclick="myFunction(this.id)"></i>
    </a>
    </li>
</ul>
</div>
  <div class="col-12 cail">

    <h1 id="cail"><a href="{{site.url}}/manifesto">The <br> Critical AI <br> Manifesto</a></h1>

  </div>

</div>

<div class="row">


    <div class="col-6">
        <h2 id="cail"><a href="#about">about</a></h2>

        <p>On this page are some resources for Critical AI Literacy (CAIL) from <a href="{{site.url}}">my perspective</a>.
            Also see: <a href="https://www.ru.nl/en/research/research-projects/critical-ai-literacy-cail">the project homepage</a> and
            <a href="https://www.ru.nl/en/research/research-news/opposing-the-inevitability-of-ai-at-universities-is-possible-and-necessary">this press release</a> on our work<a href=""></a>.</p>

        <p>As we say <a href="https://www.civicsoftechnology.org/blog/no-ai-gods-no-ai-masters">here</a>,  CAIL is:
            <blockquote>an umbrella for all the prerequisite knowledge required to have an expert-level critical perspective, such as to tell apart nonsense hype from true theoretical computer scientific claims (see our <a href="https://www.ru.nl/en/research/research-projects/critical-ai-literacy-cail">project website</a>). For example, the idea that human-like systems are a sensible or possible goal is the result of circular reasoning and anthropomorphism. Such kinds of realisations are possible only when one is educated on the principles behind AI that stem from the intersection of computer and cognitive science, but cannot be learned if interference from the technology industry is unimpeded. Unarguably, rejection of this nonsense is also possible through other means, but in our context our AI students and colleagues are often already ensnared by uncritical computationalist ideology. We have the expertise to fix that, but not always the institutional support.</blockquote>
            
        </p>

        </div>


    <div class="col-6">
        <h2 id="cail"><a href="#about">about</a></h2>

        <p>On this page are some resources for Critical AI Literacy (CAIL) from <a href="{{site.url}}">my perspective</a>.
            Also see: <a href="https://www.ru.nl/en/research/research-projects/critical-ai-literacy-cail">the project homepage</a> and
            <a href="https://www.ru.nl/en/research/research-news/opposing-the-inevitability-of-ai-at-universities-is-possible-and-necessary">this press release</a> on our work<a href=""></a>.</p>

        <p>As we say <a href="https://www.civicsoftechnology.org/blog/no-ai-gods-no-ai-masters">here</a>,  CAIL is:
            <blockquote>an umbrella for all the prerequisite knowledge required to have an expert-level critical perspective, such as to tell apart nonsense hype from true theoretical computer scientific claims (see our <a href="https://www.ru.nl/en/research/research-projects/critical-ai-literacy-cail">project website</a>). For example, the idea that human-like systems are a sensible or possible goal is the result of circular reasoning and anthropomorphism. Such kinds of realisations are possible only when one is educated on the principles behind AI that stem from the intersection of computer and cognitive science, but cannot be learned if interference from the technology industry is unimpeded. Unarguably, rejection of this nonsense is also possible through other means, but in our context our AI students and colleagues are often already ensnared by uncritical computationalist ideology. We have the expertise to fix that, but not always the institutional support.</blockquote>
            
        </p>

        </div>
</div>


<div class="menu-and-main"><div>
<div class="menu fixed">
        <h2 id="toc"><a href="#toc">contents</a></h2>

        <ol>
            <li>
                Introduction
            </li>
        </ol>        
  
</div></div>

<div class="main-container">
<div class="row">


    <div class="col-12">


        <h2 id="cail"><a href="#about">about</a></h2>

        <p>On this page are some resources for Critical AI Literacy (CAIL) from <a href="{{site.url}}">my perspective</a>.
            Also see: <a href="https://www.ru.nl/en/research/research-projects/critical-ai-literacy-cail">the project homepage</a> and
            <a href="https://www.ru.nl/en/research/research-news/opposing-the-inevitability-of-ai-at-universities-is-possible-and-necessary">this press release</a> on our work<a href=""></a>.</p>

        <p>As we say <a href="https://www.civicsoftechnology.org/blog/no-ai-gods-no-ai-masters">here</a>,  CAIL is:
            <blockquote>an umbrella for all the prerequisite knowledge required to have an expert-level critical perspective, such as to tell apart nonsense hype from true theoretical computer scientific claims (see our <a href="https://www.ru.nl/en/research/research-projects/critical-ai-literacy-cail">project website</a>). For example, the idea that human-like systems are a sensible or possible goal is the result of circular reasoning and anthropomorphism. Such kinds of realisations are possible only when one is educated on the principles behind AI that stem from the intersection of computer and cognitive science, but cannot be learned if interference from the technology industry is unimpeded. Unarguably, rejection of this nonsense is also possible through other means, but in our context our AI students and colleagues are often already ensnared by uncritical computationalist ideology. We have the expertise to fix that, but not always the institutional support.</blockquote>
            
        </p>

        <p>CAIL also has the goal to repatriate university technological infrastructure and protect our students and selves from deskilling — as we explain <a href="https://www.ru.nl/en/research/research-news/opposing-the-inevitability-of-ai-at-universities-is-possible-and-necessary">here</a>: 
            
            <blockquote>Within just a few years, AI has turbocharged the spread of bullshit and falsehoods. It is not able to produce actual, qualitative academic work, despite the claims of some in the AI industry. As researchers, as universities, we should be clearer about pushing back against these false claims by the AI industry. We are told that AI is inevitable, that we must adapt or be left behind. But universities are not tech companies. Our role is to foster critical thinking, not to follow industry trends uncritically.</blockquote>
        See more at — and please cite — the preprint here:
        {% assign article = site.data.publications | where: 'doi', '10.5281/zenodo.17065099' %}
        {% include publications_copy.html publications=article %}</p>

            <p>Here is a wonderfully done interview by <a href="https://www.the-geyser.com/pod-interview-with-olivia-guest-and-iris-van-rooij/">Kent Anderson and Joy Moore</a>, where we got to speak at length on these topics:
            
            <div class="videoWrapper">
                <iframe width="560" height="315" src="https://www.youtube.com/embed/p9w0FiHo1RU?si=yAykif0IShwbNn8d" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
            </div></p>

            <p>In general, have a look at the various resources here, such as the <a href="#blogs">blog posts</a> and <a href="#research">preprints and published papers</a> to understand our various perspectives.</p>
    </div>


</div>
</div>


</div>





</article>
