---
layout: default
title: Critical AI
permalink: /ai
published: true
image: /images/cail_banner.png
css: ai
description: "On this page are some resources for Critical AI Literacy (CAIL) from my perspective."
mermaid: true
---




<article class="page">

<div class="row">
  <div class="col-12 header" id="header">

    <h1><a href="{{site.url}}/ai">Critical AI</a></h1>

  </div>
</div>

<div class="row">

    <div class="col-12">
        <h2 id="2026"><a href="#2026">2026 summer course</a></h2>
    </div>
    <div class="col-12 col-6-md col-6-lg">

        <h3 id="course"><a href="#course">critical AI literacies for resisting and reclaiming</a></h3>


        <p>This summer, we will be running a course for professionals and academics on detecting, overcoming, and surpassing nonsense AI claims.</p>

        <p><b>For more information and to apply, see the <a href="https://www.ru.nl/en/education/education-for-professionals/overview/critical-ai-literacies-for-resisting-and-reclaiming">Radboud website for this course</a>.</b></p>
    </div>

     <div class="col-12 col-6-md col-6-lg vertical-center hide-xs hide-sm vertical-center"> 
        <img src="{{ site.baseurl }}/images/The wonders of optics - Fig 24.png" alt="icon"  class="hide-xs hide-sm decor">
        <p class="hide-xs hide-sm caption">Camille Flammarion, <a href="https://en.wikisource.org/wiki/The_wonders_of_optics/The_laws_of_reflection.%E2%80%94Mirrors">The wonders of optics</a> (1871)</p>

    </div>

</div>


<div class="row">

        <div class="col-12">
        <h2 id="cail" class="letsgo" data-text="what is critical AI literacy?"><a href="#cail">what is critical AI literacy?</a></h2>
        </div>

    <div class="col-12 col-6-md col-6-lg">



        <h3 id="about"><a href="#about">about</a></h3>

        <p>On this page are some resources for Critical AI Literacy (CAIL) from <a href="{{site.url}}">my perspective</a>.
            Also see: <a href="https://www.ru.nl/en/research/research-projects/critical-ai-literacy-cail">the project homepage</a> and
            <a href="https://www.ru.nl/en/research/research-news/opposing-the-inevitability-of-ai-at-universities-is-possible-and-necessary">this press release</a> on our work<a href=""></a>.</p>

        <p>As we say <a href="https://www.civicsoftechnology.org/blog/no-ai-gods-no-ai-masters">here</a>,  CAIL is:
            <blockquote>an umbrella for all the prerequisite knowledge required to have an expert-level critical perspective, such as to tell apart nonsense hype from true theoretical computer scientific claims (see our <a href="https://www.ru.nl/en/research/research-projects/critical-ai-literacy-cail">project website</a>). For example, the idea that human-like systems are a sensible or possible goal is the result of circular reasoning and anthropomorphism. Such kinds of realisations are possible only when one is educated on the principles behind AI that stem from the intersection of computer and cognitive science, but cannot be learned if interference from the technology industry is unimpeded. Unarguably, rejection of this nonsense is also possible through other means, but in our context our AI students and colleagues are often already ensnared by uncritical computationalist ideology. We have the expertise to fix that, but not always the institutional support.</blockquote>
            
        </p>

        <p>CAIL also has the goal to repatriate university technological infrastructure and protect our students and selves from deskilling — as we explain <a href="https://www.ru.nl/en/research/research-news/opposing-the-inevitability-of-ai-at-universities-is-possible-and-necessary">here</a>: 
            
            <blockquote>Within just a few years, AI has turbocharged the spread of bullshit and falsehoods. It is not able to produce actual, qualitative academic work, despite the claims of some in the AI industry. As researchers, as universities, we should be clearer about pushing back against these false claims by the AI industry. We are told that AI is inevitable, that we must adapt or be left behind. But universities are not tech companies. Our role is to foster critical thinking, not to follow industry trends uncritically.</blockquote>
        See more at — and please cite — the preprint here:
        {% assign article = site.data.publications | where: 'doi', '10.5281/zenodo.17065099' %}
        {% include publications.html publications=article %}</p>

            <!-- <p>Here is a wonderfully done interview by <a href="https://www.the-geyser.com/pod-interview-with-olivia-guest-and-iris-van-rooij/">Kent Anderson and Joy Moore</a>, where we got to speak at length on these topics: <a href="https://www.youtube.com/watch?v=p9w0FiHo1RU">Safeguarding Science from AI: An Interview with Olivia Guest and Iris van Rooij</a>. -->
            
            <!-- <div class="videoWrapper">
                <iframe width="560" height="315" src="https://www.youtube.com/embed/p9w0FiHo1RU?si=yAykif0IShwbNn8d" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
            </div> -->
        <!-- </p>

            <p> -->
                
                In general, have a look at the various resources here, such as the <a href="#blogs">blog posts</a> and <a href="#research">preprints and published papers</a> to understand our various perspectives.</p>
                <div class="vertical-center">

                        <img src="{{ site.baseurl }}/images/The_wonders_of_optics_-_Fig_32.png" alt="icon"  class="hide-xs hide-sm decor">
                        <p class="hide-xs hide-sm caption">Camille Flammarion, <a href="https://en.wikisource.org/wiki/The_wonders_of_optics/">The wonders of optics</a> (1871)</p>
                </div>

    <h3 id="talks"><a href="#talks">video talks & interviews</a></h3>

        {% assign talks = site.data.publications | sort:"date" | reverse | where: 'tags', 'cail' | where: 'selected', '4' %}
        {% include publications.html publications=talks %}
        <div class="vertical-center">
                <img src="{{ site.baseurl }}/images/Merian.png" alt="icon" id="butterflies" class="is-center hide-xs hide-sm decor">
                <p class="hide-xs hide-sm caption"><a href="https://en.wikipedia.org/wiki/Maria_Sibylla_Merian">Maria Sibylla Merian</a>; Erucarum Ortus (1679–1717)</p>

        </div>

    </div>
    <div class="col-12 col-6-md col-6-lg">


        <h3 id="blogs"><a href="#blogs">blog posts, news, & opinion pieces</a></h3>

        {% assign blogs = site.data.publications | sort:"date" | reverse | where: 'tags', 'cail'  | where: 'selected', '3' %}
        {% include publications.html publications=blogs %}
        
        <h3 id="research"><a href="#research">research</a></h3>

        {% assign articles = site.data.publications | sort:"date" | reverse | where: 'tags', 'cail'  | where: 'selected', '1' %}
        {% include publications.html publications=articles %}

        
    </div>

</div>

<!-- {% comment %}

<div class="row">

    <div class="col-12">
        <h3 id="map"><a href="#map">mindmap of CAILs</a></h3>
        <div class="mermaid is-center">
            {% include map.md %}
        </div>
         <div class="extract is-center"><p>
            The map above is adapted from a version created by <a href="https://www.setu.ie/staff/colm-oneill">Colm O'Neill</a>; and is based inter alia on work above. It is under construction as the original had quotes per leaf node. Changes can be suggested <a href="https://github.com/oliviaguest/oliviaguest.github.io/blob/main/_includes/map.md">here</a>.
        </p>
    </div>
</div>
</div>{% endcomment %}
 -->




<div class="row">


    <div class="col-12">
    <h2 id="cail" class="featured work" data-text=""><a href="#featured">featured research</a></h2>
    </div>

</div>



<div class="row">


    <div class="col-12">

        <h3 id="pygmalion"><a href="#pygmalion">Pygmalion Displacement: When Humanising AI Dehumanises Women</a></h3>

            <div class="is-center">
            <div class="cite is-center">
                {% assign article = site.data.publications | where:"title","Pygmalion Displacement: When Humanising AI Dehumanises Women" %}
                {% include publications.html publications=article %}</div>
            </div>

    </div>


    <div class="col-12 col-7-md col-7-lg vertical-center">
        <img src="{{ site.baseurl }}/images/ErscoiKleinherenbrinkGuest_timeline.png" alt="icon" class="figure is-center" id="cails">

        <div class="extract is-center"><p>"This figure depicts, in the style of a printed circuit board, a timeline of events (many with related images) that involve Pygmalion displacement in one form or another. On the left [are] fictional instances of women’s and automata’s intertwined identities; from 1901 at the top to today’s film and television series at the bottom. On the right [are] historical individuals or artefacts." (<a href="//doi.org/10.31235/osf.io/jqxb6 ">Guest et al., 2023</a>, figure 2)</p></div>

    </div>

    <div class="col-12 col-5-md col-5-lg">
        <p><span class="abstract-label">Abstract:</span>
            We use the myth of Pygmalion as a lens to investigate and frame the relationship between women and artificial intelligence (AI). Pygmalion was a legendary ancient king of Cyprus and sculptor. Having been repulsed by women, he used his skills to create a statue, which was imbued with life by the goddess Aphrodite. This can be seen as one of the primordial AI-like myths, wherein humanity creates intelligent life-like self-images to reproduce or replace ourselves. In addition, the myth prefigures historical and present gendered dynamics within the field of AI and between AI and society at large. Throughout history, the theme of women being replaced by inanimate objects (e.g. automata, algorithms) has been repeated, and continues to repeat in contemporary AI technologies. However, this socially detrimental pattern in technology — what we dub Pygmalion displacement — is often overlooked, whether due to naive excitement about new developments, or due to an unacknowledged sexist history of the field itself. As we demonstrate herein, Pygmalion displacement prefigures heavily, but in an unacknowledged way, in the original Turing test, the imitation game: a central thought experiment, foundational to AI. With women, and the feminine generally, being both dislocated and erased from and by technology, AI is and has been (presented as) created mainly by privileged men, subserving capitalist patriarchal ends. This poses serious dangers to women and other marginalised people. By tracing the historical and ongoing entwinement of femininity (from a patriarchal perspective) and AI, we aim to understand, make visible, and start a dialogue on the ways in which AI harms women.</p>

    </div> 
    <div class="col-12 col-3-md col-3-lg vertical-separate">


            <div class="extract"><p>"The series of questions that comprise the Pygmalion lens. For a given technosocial relationship between AI and people,if one or more of the answers are “Yes”, then we can conclude that (an aspect of) Pygmalion displacement is occurring, which is damaging to women, and the feminised broadly construed.  If not, then the lens does not apply, and we remain agnostic as to gendered or other harm within this framework.  Our proverbial lens should be taken inter alia to be akin to an optical lens which allows for the eye to see more details than when naked, as depicted in the line drawing below." (<a href="//doi.org/10.31235/osf.io/jqxb6 ">Guest et al., 2023</a>, table 1)</p></div>

            <img src="{{ site.baseurl }}/images/The_wonders_of_optics_-_Fig_32.png" alt="icon" id="lens">

    </div>

    <div class="col-12 col-9-md col-9-lg ">


        <table>
        <thead><tr><th title="Field #1" style="width: 8%; text-align: right;"></th>
        <th title="Field #2">Pygmalion Lens</th>
        <th title="Field #3" style="width: 15%"></th>
        </tr></thead>
            <tr>
                <td>1)</td>
                <td><b>Feminised form:</b> Is the AI, by its (default or exclusive) external characteristics, portraying a hegemonically feminine character?</td>
                <td>Yes/No</td>
            </tr>
            <tr>
                <td>2)</td>
                <td><b>Whitened form:</b> Is the AI, by its (default or exclusive) external characteristics, portraying a character that is inherently white (supremacist), Western, Eurocentric, etc.?</td>
                <td>Yes/No</td>
            </tr>
            <tr>
                <td>3)</td>
                <td><b>Dislocation from work:</b> Does the AI  displace women from a role or occupation, or people in general from a role or occupation that tends to be (coded as) women&#39;s work?</td>
                <td>Yes/No</td>
            </tr>
            <tr>
                <td>4)</td>
                <td><b>Humanisation via feminisation:</b> Are the AI&#39;s claims to intelligence, human-likeness or personhood contingent on stereotypical feminine traits or behaviours?</td>
                <td>Yes/No</td>
            </tr>
            <tr>
                <td>5)</td>
                <td><b>Competition with women:</b> Is the AI pit (rhetorically or otherwise) against women in ways that favour it, and which are harmful to women?</td>
                <td>Yes/No</td>
            </tr>
            <tr>
                <td>6)</td>
                <td><b>Diminishment via false equivalence:</b> Does the AI facilitate a rhetoric that deems women as not having full intellectual abilities, or as otherwise less deserving of personhood?</td>
                <td>Yes/No</td>
            </tr>
            <tr>
                <td>7)</td>
                <td><b>Obfuscation of diversity:</b> Does the AI, through displacement of specific groups of people,   “neutralise” (i.e., whiten, masculinise) a role,  vocation, or skill?</td>
                <td>Yes/No</td>
            </tr>
            <tr>
                <td>8)</td>
                <td><b>Robot rights:</b> Do the users and/or creators of the AI grant it (aspects of) legal personhood or human(-like) rights?</td>
                <td>Yes/No</td>
            </tr>
            <tr>
                <td>9)</td>
                <td><b>Social bonding:</b> Do the users and/or creators of the AI develop interpersonal-like relationships with it?</td>
                <td>Yes/No</td>
            </tr>
            <tr>
                <td>10)</td>
                <td><b>Psychological service:</b> Does the AI function to subserve and enhance the egos of its creators and/or users?</td>
                <td>Yes/No</td>
            </tr>
        </table>
    </div>

</div>

<div class="row">

    <div class="col-12">

        <h3 id="towards"><a href="#towards">Towards Critical Artificial Intelligence Literacies</a></h3>

            <div class="is-center">
            <div class="cite is-center">
                {% assign article = site.data.publications | where:"title","Towards Critical Artificial Intelligence Literacies" %}
                {% include publications.html publications=article %}</div>
            </div>

           </div>

</div>

<div class="row">
        <div class="col-12 col-7-md col-7-lg">
            <p><span class="abstract-label">Abstract:</span>
                Critical Artificial Intelligence Literacies (CAILs) is the collection of ways of thinking about and relating to so-called artificial intelligence (AI) that rejects dominant frames presented by the technology industry, by naive computationalism, and by dehumanising ideologies. Instead, CAILs centre human cognition and uphold the integrity of academic research and education. We present a selection of CAILs across research and education, which we analyse into the following non-orthogonal dimensions: <i>conceptual clarity, critical thinking, decoloniality, respecting expertise,</i> and <i>slow science</i>. Finally, we note how we see the present with and without a wider adoption of CAILs — a fundamental aspect is the assertion that AI cannot be allowed to drive change, even positive change, in education or research. Instead cultivation of and adherence to shared values and goals must guide us. Ultimately, CAILs minimally ask us to contemplate how we as academics can stop AI companies from wielding so much power.


            </p>

                <div class="extract is-center"><p>"The important dimensions of CAILs across research and education; clockwise from 12 o’clock: <i>Conceptual Clarity</i> is the idea that terms should refer. <i>Critical Thinking</i> is deep engagement with the relationships between statements about the world. <i>Decoloniality</i> is the process of de-centring and addressing dominant harmful views and practices. <i>Respecting Expertise</i> is the epistemic compact between professionals and society. <i>Slow Science</i> is a disposition towards preferring psychologically, techno-socially, and epistemically healthy practices. The lines between dimensions represent how they are interwoven both directly and indirectly." (<a href="//doi.org/10.5281/zenodo.17786243">Guest et al., 2025</a>, figure 1)</p></div>
        </div> 
    <div class="col-12 col-5-md col-5-lg vertical-center">
        <img src="{{ site.baseurl }}/images/CAILs_figure.png" alt="icon" class="figure is-center" id="cails">
    </div>
</div>


<div class="row">
    <div class="col-12">

        <h3 id="against"><a href="#against">Against the Uncritical Adoption of 'AI' Technologies in Academia</a></h3>

            <div class="is-center">
            <div class="cite is-center">
                {% assign article = site.data.publications | where:"title","Against the Uncritical Adoption of 'AI' Technologies in Academia" %}
                {% include publications.html publications=article %}</div>
            </div>

           </div>

</div>

<div class="row">

        <div class="col-12 col-5-md col-5-lg vertical-center">


                <div class="frame-figure is-center">
                    <img src="{{ site.baseurl }}/images/Sets_AI.png" alt="icon" class="figure is-center" id="sets">
                    <div class="extract is-center"><p>"A cartoon set theoretic view on various terms (see Table 1) used when discussing the superset AI"                        (<a href="https://doi.org/10.5281/zenodo.17065099">Guest et al., 2025</a>, figure 1)</p></div>
                </div>


            
        </div>

        <div class="col-12 col-7-md col-7-lg">
            <p><span class="abstract-label">Abstract:</span>
                Under the banner of progress, products have been uncritically adopted or even imposed on users — in past centuries with tobacco and combustion engines, and in the 21st with social media. For these collective blunders, we now regret our involvement or apathy as scientists, and society struggles to put the genie back in the bottle. Currently, we are similarly entangled with artificial intelligence (AI) technology. For example, software updates are rolled out seamlessly and non-consensually, Microsoft Office is bundled with chatbots, and we, our students, and our employers have had no say, as it is not considered a valid position to reject AI technologies in our teaching and research. This is why in June 2025, we co-authored an Open Letter calling on our employers to reverse and rethink their stance on uncritically adopting AI technologies. In this position piece, we expound on why universities must take their role seriously to <i>a</i>) counter the technology industry's marketing, hype, and harm; and to <i>b</i>) safeguard higher education, critical thinking, expertise, academic freedom, and scientific integrity. We include pointers to relevant work to further inform our colleagues.
                </p>

                <div class="extract is-center"><p>"Below some of the typical terminological disarray is untangled. Importantly, none of these terms are orthogonal nor do they exclusively pick out the types of products we may wish to critique or proscribe." (<a href="https://doi.org/10.5281/zenodo.17065099">Guest et al., 2025</a>, table 1)</p></div>

                
        </div>
        

    <div class="col-12">
 
        <table class="table table-bordered table-hover table-condensed">
        <thead><tr><th title="Field #1" style="width: 20%">Term</th>
        <th title="Field #2">Description</th>
        <th title="Field #3" style="">Resources</th>
        </tr></thead>
        <tbody><tr>
        <td>Artificial Intelligence (AI)</td>
        <td>The phrase &#39;artificial intelligence&#39; was coined by McCarthy et al. (1955) in the context of proposing a summer workshop at Dartmouth College in 1956. They assumed significant progress could be made on making machines think like people. In the present, AI has no fixed meaning. It can be anything from a field of study to a piece of software.</td>
        <td>Avraamidou (2024), Bender and Hanna (2025), Bloomfield (1987), Boden (2006), Brennan et al. (2025), Crawford (2021), Guest (2025), Hao (2025), McCorduck (2004), McQuillan (2022), Monett (2021), Vallor (2024), and van Rooij, Guest, et al. (2024).</td>
        </tr>
        <tr>
        <td>Artificial neural network (ANN)</td>
        <td>First proposed in McCulloch and Pitts (1943), it is a mathematical model, comprised of interconnected banks of units that perform matrix multiplication and non-linear functions. These statistical models are exposed to data (input-output pairs) that they aim to reproduce. While held to be inspired by the brain, such claims are tenuous or misleading.</td>
        <td>Abraham (2002), Bishop (2021), Boden (2006), Dhaliwal et al. (2024), Guest and Martin (2023, 2025a), Hamilton (1998), Stinson (2018, 2020), and Wilson (2016).</td>
        </tr>
        <tr>
        <td>Chatbot</td>
        <td>An engineered system that appears to converse with the user using text or voice. Speech synthesis goes back hundreds of years (Dudley 1939; Gold 1990; Schroeder 1966) and Weizenbaum&#39;s (1966) ELIZA is considered the first chatbot (Dillon 2020). Modern versions can contain ANNs in addition to hardcoded rules.</td>
        <td>Bates (2025), Dillon (2020), Elder (2022), Erscoi et al. (2023), Schlesinger et al. (2018), Strengers et al. (2024), Turkle (1984), and Turkle et al. (2006).</td>
        </tr>
        <tr>
        <td>ChatGPT</td>
        <td>A proprietary closed source chatbot created by OpenAI. The for-profit company OpenAI has been steeped in hype from inception. It does not provide source code for most of its models, violating open science principles for academic users. OpenAI reported $5 billion in losses in 2024 (Reuters 2025), and has received $13 billion from Microsoft (Levine 2024).</td>
        <td>Andhov (2025), Birhane and Raji (2022), Dupré (2025), Gent (2024), M. T. Hicks et al. (2024), Hill  (2025), Jackson (2024), Kapoor et al. (2024), Liesenfeld, Lopez, et al. (2023), Mirowski (2023), Perrigo (2023), Titus (2024), and Widder et al. (2024).</td>
        </tr>
        <tr>
        <td>Generative model</td>
        <td>A specification on the type of statistical distribution modelled; typically contrasted with discriminative model. ANNs can be generative (e.g. Boltzmann machines) or discriminative (e.g. convolutional neural networks used for classifying images). In the context of generative AI or generative pre-trained transformer (GPT), this phrase is used inconsistently.</td>
        <td>Efron (1975), Jebara (2004), Mitchell (1997), Ng and Jordan (2001), and Xue and Titterington (2008).</td>
        </tr>
        <tr>
        <td>Large language model (LLM)</td>
        <td>A model that captures some aspect of language, with the term &#39;large&#39; denoting that the number of parameters exceed a certain threshold. Modern chatbots are often LLMs, which use ANNs, along with a graphical interface so that users can input so-called text &#39;prompts.&#39; LLMs can be generative, discriminative, or neither.</td>
        <td>Bender, Gebru, et al. (2021), Birhane and McGann (2024),Dentella et al. (2023, 2024), Leivada, Dentella, et al. (2024), Leivada, Günther, et al. (2024), Luitse and Denkena (2021), Shojaee et al. (2025a), Villalobos et al. (2024), and Wang et al. (2024)</td>
        </tr>
        </tbody></table>
    </div>
</div>


<div class="row">
    <div class="col-12">

        <h3 id="psych"><a href="#psych">Critical Artificial Intelligence Literacy for Psychologists</a></h3>

            <div class="is-center">
            <div class="cite is-center">
                {% assign article = site.data.publications | where:"title","Critical Artificial Intelligence Literacy for Psychologists" %}
                {% include publications.html publications=article %}</div>
            </div>

           </div>

</div>

<div class="row">
        <div class="col-12 col-4-md col-4-lg">
            <p><span class="abstract-label">Abstract:</span>
                Psychologists — from computational modellers to social and personality researchers to cognitive neuroscientists and from experimentalists to methodologists to theoreticians — can fall prey to exaggerated claims about artificial intelligence (AI).
                In social psychology, as in psychology generally, we see arguments taken at face value for: <i>a</i>) the displacement of experimental participants with opaque AI products;
                the outsourcing of <i>b</i>) programming, <i>c</i>) writing, and even <i>d</i>) scientific theorising to such models;
                and the notion that <i>e</i>) human-technology interactions could be on the same footing as human-human (e.g., client-therapist, student-teacher, patient-doctor, friendship, or romantic) relationships.
                But if our colleagues are, accidentally or otherwise, promoting such ideas in exchange for salary, grants, or citations, how are we as academic psychologists meant to react?
                Formal models, from statistics and computational methods broadly, have a potential obfuscatory power that is weaponisable, laying serious traps for the uncritical adopters, with even the term `AI' having murky referents.
                Herein, we concretise the term AI and counter the five related proposals 
                above — from the clearly insidious to those whose ethical neutrality is skin-deep and whose functionality is a mirage.
                Ultimately, contemporary AI is research misconduct.</p>

                <div class="extract is-center"><p>"Core reasoning issues (first column), which we name after the relevant numbered section, are characterised using a plausible quote. In the second column are responses per row; also see the named section for further reading, context, and explanations." (<a href="//doi.org/10.31234/osf.io/dkrgj_v1">Guest & van Rooij, 2025</a>, table 1)</p></div>
        </div> 
    <div class="col-12 col-8-md col-8-lg">
 
        <table class="table table-bordered table-hover table-condensed">
        <thead><tr><th title="Field #1" style="width: 25%">Uncritical Statement</th>
        <th title="Field #2">Possible Response</th>
        </tr></thead>
        <tbody><tr>
        <td><b>Lies, Damned Lies, and Statistics</b><br><br> &quot;AI products are outside my expertise but I think it is useful to deploy them.&quot;</td>
        <td class="text-justify">As a matter of fact these products are statistical models, akin to logistic regression, which all psychologists even undergraduate students are required to have a familiarity with. Additionally, it is required to know the differences between models used to perform statistical inference and those that are models of cognition. As is knowing basic open science principles. Therefore, it should come as no shock that  assuming the mantle of the non-expert here is inappropriate, and in fact may even be a form of QRP to abandon critical thinking.</td>
        </tr>
        <tr>
        <td><b>Displacement of Participants</b><br><br>&quot;I can use AI instead of participants to perform tasks and generate data.&quot;</td>
        <td class="text-justify">The provenance of the data used in these models indicates it is not ethically sourced, falling below standards for our discipline, involving sweatshop labour and no consent for private data used in experiments. The output can contain direct original input data (i.e. double dipping), but smoothed to remove outliers, conform to our pre-existing ideas of what it should look like (data fabrication), and all-round irreplicable. Psychology is meant to study humans, not patterns at the output of biased statistical models.</td>
        </tr>
        <tr>
        <td><b>Outsourcing Programming to Companies</b><br><br>&quot;I can use AI for programming experimental paradigms and statistical analyses.&quot;</td>
        <td class="text-justify">This is an example of the field’s backsliding from adopting open science and programming skills. No formal specification will be given for code generated from a corporate-owned opaque model. The psychologist now has no reason to learn how to engineer software, and disturbingly might as well switch back to propriety software like SPSS which at least has documentation and explicit versions. Code at the output will be plagiarised, making it time-consuming to check compliance with our needs than if we wrote the code ourselves, and violating openness.</td>
        </tr>
        <tr>
        <td><b>Ghostwriter in the Machine</b><br><br>&quot;I can use AI for understanding the literature and for scholarly writing.&quot;</td>
        <td class="text-justify">This practice implicates a swathe of issues akin to automating the paper mill. First, the literature is screened by corporations, which have every reason to control the output of the model to suit their needs or minimally to ignore output issues, such as sexism. Second, the fabrication of non-existent citations which makes claims worse than baseless because they appear supported by prior work. Third, the dislocation of text from the literature since no provenance can be established, resulting in plagiarism.</td>
        </tr>
        <tr>
        <td><b>The End of Scientific Theory</b><br><br>&quot;I can outsource verbal theorising to AI or use it as a formal cognitive model.&quot;</td>
        <td class="text-justify">This not only adds to the dislocation of work from its evidential and historical basis, but also it impedes our theorising about phenomena and systems under study. In this context, we are interested in human-understandable theory and theory-based models, not statistical models which provide only a representation of the data. Scientific theories and models are only useful if we, the scientists who build and use them, understand them in deep ways and they connect transparently to research questions. AI product use is absconding scientific duty.</td>
        </tr>
        <tr>
        <td><b>Equivocation of Human-Human &amp; Human-AI</b><br><br>&quot;I can study people using chatbots as if they are socially interacting.&quot;</td>
        <td class="text-justify">Seeing client-therapist, student-teacher, patient-doctor, friendship, or romantic relationships as equivalent to those between people and artifacts is both a form of dehumanisation and a hollowing out of the target of study in social psychology: the relationship between people and other people. It is important to study the relations between humanity and machines and the social interactions mediated through technology — but to place interactions with chatbots in the same category as those between people assumes and risks too much.</td>
        </tr>
        </tbody></table>
</div></div>



<!-- <div class="row">
    <div class="col-12">
        <img class="poster is-full-width" src="{{ site.baseurl }}/images/anti-ai2.jpg" alt="icon" />
   </div>
   
   <div class="col-12">
        <img class="poster is-full-width" src="{{ site.baseurl }}/images/anti-ai1.jpg" alt="icon" />
   </div>
</div> -->

<div class="row">

    <div class="col-12 allies">

      <h2 id="allies"><a href="#allies">allies & resources</a></h2>
</div></div>

<div class="row">
    <div class="col-12 col-6-md col-6-lg vertical-center hide-xs hide-sm vertical-center"> 
        <img src="{{ site.baseurl }}/images/The_wonders_of_optics_-_Fig_25.png" alt="icon"  class="hide-xs hide-sm decor">
        <p class="hide-xs hide-sm caption">Camille Flammarion, <a href="https://en.wikisource.org/wiki/The_wonders_of_optics/Metallic_burning_mirrors">The wonders of optics</a> (1871)</p>
    </div>

    <div class="col-12 col-6-md col-6-lg">
        <p>Here are some related academics' and scholars' websites (feel free to contact me to add more):</p>
        <ul>
            <li><a href="https://refusinggenai.wordpress.com/">Refusing GenAI in Writing Studies: A Quickstart Guide</a>, by Jennifer Sano-Franchini, Megan McIntyre, & Maggie Fernandes.</li>
            <li><a href="https://against-a-i.com/">AGAINST AI</a>, by Anna Kornbluh, Krista Muratore, & Eric Hayot.</li>
            <li><a href="https://monroelab.com/">Computational Impacts: Tech Industry Critique Without Tech-bro-ism</a>, by Dwayne Monroe.</li>
            <li><a href="https://stopgenai.com/">Stop Gen AI</a>, by Kim Crawley.</li>
            <li><a href="https://www.skwinnicki.com/single-post/i-would-be-so-ashamed-to-use-generative-ai-here-s-why">I would be so ashamed to use generative AI, here’s why</a>, by Sarah Winnicki.</li>
        
        </ul>

   </div>

</div>

<div class="row">

    <div class="col-12  activism">

      <h2 id="activism"><a href="#activism">activism & posters</a></h2>
</div></div>

<div class="row">

  <div class="col-12 col-6-md col-6-lg">
    <!-- <h3 id="letter"><a href="#letter">sign the Open Letter</a></h3> -->

    <h3 id="letter">Open Letters</h3>

    <p>Colleagues and I have written and published: <a href="https://openletter.earth/open-letter-stop-the-uncritical-adoption-of-ai-technologies-in-academia-b65bba1e?limit=0"><i>Open Letter: Stop the Uncritical Adoption of AI Technologies in Academia</i></a>.</p>

    <p>
    Please consider adapting the letter for your employer; here are some allies' efforts inspired by our letter:<ul>
        <li>
            <i><a href="https://openletter.earth/an-open-letter-from-educators-who-refuse-the-call-to-adopt-genai-in-education-cb4aee75">An open letter from educators who refuse the call to adopt GenAI in education</a></i>, by <a href="https://www.findlay.edu/search/faculty-staff?fsid=00002a38+">Melanie Dusseau</a> and <a href="https://miriamreynoldson.com/">Miriam Reynoldson</a>.
        </li>
        <li>
            <i><a href="https://openletter.earth/stop-ai-in-malden-schools-d7de618d">Stop AI in Malden Schools</a></i> — against AI use Malden, Greater Boston, MA, USA.
        </li>
    <li>
    <a href="https://linktr.ee/sabrinamittermeier">Sabrina Mittermeier</a> created a German version of our letter: <i><a href="https://openletter.earth/gegen-die-unkritische-anwendung-und-implementierung-sog-kunstlicher-intelligenz-ki-in-der-deutschen-wissenschaft-und-im-hochschulalltag-3094a789">Gegen die unkritische Anwendung und Implementierung sog. Künstlicher Intelligenz (KI) in der deutschen Wissenschaft und im Hochschulalltag</a></i>.  
    </li>
    </ul>
    </p>

     </div>
    



    <div class="col-12 col-6-md col-6-lg"> 
        <!-- <h3 id="posters"><a href="#posters">have you considered not using AI?</a></h3> -->
        <h3 id="posters">have you considered not using AI?</h3>


        <p>I made some posters, in the style of this website, to use to attract attention to more critical thinking about AI: <b>Download them as <a href="https://doi.org/10.5281/zenodo.17112000">PDFs here</a>.</b> The QR code points to:         {% assign article = site.data.publications | where: 'doi', '10.5281/zenodo.17065099' %}
        {% include publications.html publications=article %}</p>
    </div>


</div>

<div class="row" id="deco-row">
  <div class="col-12 vertical-center" id="deco-footer">

    <a href="https://doi.org/10.5281/zenodo.17112000">Have you considered <br> NOT using <br> AI?</a>

  </div>
</div>

<!-- <div class="row">
    <div class="col-4">
        <img src="{{ site.baseurl }}/images/anti-ai1.png" alt="icon" class="poster is-full-width">

   </div>
   <div class="col-4">
        <img src="{{ site.baseurl }}/images/anti-ai2.png" alt="icon" class="poster is-full-width">

   </div>
   <div class="col-4">
        <img src="{{ site.baseurl }}/images/anti-ai3.png" alt="icon" class="poster is-full-width">
   </div>
</div>

<div class="row">
    <div class="col-6">
        <img src="{{ site.baseurl }}/images/anti-ai4.png" alt="icon" class="poster is-full-width">

   </div>
   <div class="col-6">
        <img src="{{ site.baseurl }}/images/anti-ai5.png" alt="icon" class="poster is-full-width">

   </div>
</div> -->




</article>
