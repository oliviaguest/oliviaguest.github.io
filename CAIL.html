---
layout: default
title: Critical AI
permalink: /ai
published: true
image: /images/cail_banner.png
css: ai
description: "On this page are some resources for Critical AI Literacy (CAIL) from my perspective."

---


<article class="page">

<div class="row">
  <div class="col-12 header">

    <h1 id="header"><a href="{{site.url}}/ai">Critical AI</a></h1>

  </div>
</div>

<div class="row">

        <div class="col-12">
        <h2 id="cail"><a href="#cail">what is critical AI literacy?</a></h2>
        </div>

    <div class="col-12 col-6-md col-6-lg">

        <h3 id="about"><a href="#about">about</a></h3>

        <p>On this page are some resources for Critical AI Literacy (CAIL) from <a href="{{site.url}}">my perspective</a>.
            Also see: <a href="https://www.ru.nl/en/research/research-projects/critical-ai-literacy-cail">the project homepage</a> and
            <a href="https://www.ru.nl/en/research/research-news/opposing-the-inevitability-of-ai-at-universities-is-possible-and-necessary">this press release</a> on our work<a href=""></a>.</p>

        <p>As we say <a href="https://www.civicsoftechnology.org/blog/no-ai-gods-no-ai-masters">here</a>,  CAIL is:
            <blockquote>an umbrella for all the prerequisite knowledge required to have an expert-level critical perspective, such as to tell apart nonsense hype from true theoretical computer scientific claims (see our <a href="https://www.ru.nl/en/research/research-projects/critical-ai-literacy-cail">project website</a>). For example, the idea that human-like systems are a sensible or possible goal is the result of circular reasoning and anthropomorphism. Such kinds of realisations are possible only when one is educated on the principles behind AI that stem from the intersection of computer and cognitive science, but cannot be learned if interference from the technology industry is unimpeded. Unarguably, rejection of this nonsense is also possible through other means, but in our context our AI students and colleagues are often already ensnared by uncritical computationalist ideology. We have the expertise to fix that, but not always the institutional support.</blockquote>
            
        </p>

        <p>CAIL also has the goal to repatriate university technological infrastructure and protect our students and selves from deskilling — as we explain <a href="https://www.ru.nl/en/research/research-news/opposing-the-inevitability-of-ai-at-universities-is-possible-and-necessary">here</a>: 
            
            <blockquote>Within just a few years, AI has turbocharged the spread of bullshit and falsehoods. It is not able to produce actual, qualitative academic work, despite the claims of some in the AI industry. As researchers, as universities, we should be clearer about pushing back against these false claims by the AI industry. We are told that AI is inevitable, that we must adapt or be left behind. But universities are not tech companies. Our role is to foster critical thinking, not to follow industry trends uncritically.</blockquote>
        See more at — and please cite — the preprint here:
        {% assign article = site.data.publications | where: 'doi', '10.5281/zenodo.17065099' %}
        {% include publications_copy.html publications=article %}</p>

            <p>Here is a wonderfully done interview by <a href="https://www.the-geyser.com/pod-interview-with-olivia-guest-and-iris-van-rooij/">Kent Anderson and Joy Moore</a>, where we got to speak at length on these topics: <a href="https://www.youtube.com/watch?v=p9w0FiHo1RU">Safeguarding Science from AI: An Interview with Olivia Guest and Iris van Rooij</a>.
            
            <!-- <div class="videoWrapper">
                <iframe width="560" height="315" src="https://www.youtube.com/embed/p9w0FiHo1RU?si=yAykif0IShwbNn8d" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
            </div> -->
        <!-- </p>

            <p> -->
                
                In general, have a look at the various resources here, such as the <a href="#blogs">blog posts</a> and <a href="#research">preprints and published papers</a> to understand our various perspectives.</p>

                        <h3 id="talks"><a href="#talks">talks & interviews</a></h3>

        {% assign talks = site.data.publications | sort:"date" | reverse | where: 'tags', 'cail' | where: 'selected', '4' %}
        {% include publications_copy.html publications=talks %}
    </div>
    <div class="col-12 col-6-md col-6-lg">


        <h3 id="blogs"><a href="#blogs">blogs & opinion pieces</a></h3>

        {% assign blogs = site.data.publications | sort:"date" | reverse | where: 'tags', 'cail'  | where: 'selected', '3' %}
        {% include publications_copy.html publications=blogs %}
        
        <h3 id="research"><a href="#research">research</a></h3>

        {% assign articles = site.data.publications | sort:"date" | reverse | where: 'tags', 'cail'  | where: 'selected', '1' %}
        {% include publications_copy.html publications=articles %}

        
    </div>

</div>


<div class="row">
    <div class="col-12">

        <h3 id="psych"><a href="#psych">Critical Artificial Intelligence Literacy for Psychologists</a></h3>

            <div class="is-center">
            <div class="cite is-center">
                {% assign article = site.data.publications | where:"title","Critical Artificial Intelligence Literacy for Psychologists" %}
                {% include publications_copy.html publications=article %}</div>
            </div>

           </div>

</div>

<div class="row">
        <div class="col-12 col-4-md col-4-lg">
            <p><span class="abstract-label">Abstract:</span>
                Psychologists — from computational modellers to social and personality researchers to cognitive neuroscientists and from experimentalists to methodologists to theoreticians — can fall prey to exaggerated claims about artificial intelligence (AI).
                In social psychology, as in psychology generally, we see arguments taken at face value for: <i>a</i>) the displacement of experimental participants with opaque AI products;
                the outsourcing of <i>b</i>) programming, <i>c</i>) writing, and even <i>d</i>) scientific theorising to such models;
                and the notion that <i>e</i>) human-technology interactions could be on the same footing as human-human (e.g., client-therapist, student-teacher, patient-doctor, friendship, or romantic) relationships.
                But if our colleagues are, accidentally or otherwise, promoting such ideas in exchange for salary, grants, or citations, how are we as academic psychologists meant to react?
                Formal models, from statistics and computational methods broadly, have a potential obfuscatory power that is weaponisable, laying serious traps for the uncritical adopters, with even the term `AI' having murky referents.
                Herein, we concretise the term AI and counter the five related proposals 
                above — from the clearly insidious to those whose ethical neutrality is skin-deep and whose functionality is a mirage.
                Ultimately, contemporary AI is research misconduct.</p>

                <div class="extract is-center"><p>"Core reasoning issues (first column), which we name after the relevant numbered section, are characterised using a plausible quote. In the second column are responses per row; also see the named section for further reading, context, and explanations." (<a href="http://doi.org/10.31234/osf.io/dkrgj_v1">Guest & van Rooij, 2025</a>, table 1)</p></div>
        </div> 
    <div class="col-12 col-8-md col-8-lg">
 
        <table class="table table-bordered table-hover table-condensed">
        <thead><tr><th title="Field #1" style="width: 25%">Uncritical Statement</th>
        <th title="Field #2">Possible Response</th>
        </tr></thead>
        <tbody><tr>
        <td><b>Lies, Damned Lies, and Statistics</b><br><br> &quot;AI products are outside my expertise but I think it is useful to deploy them.&quot;</td>
        <td class="text-justify">As a matter of fact these products are statistical models, akin to logistic regression, which all psychologists even undergraduate students are required to have a familiarity with. Additionally, it is required to know the differences between models used to perform statistical inference and those that are models of cognition. As is knowing basic open science principles. Therefore, it should come as no shock that  assuming the mantle of the non-expert here is inappropriate, and in fact may even be a form of QRP to abandon critical thinking.</td>
        </tr>
        <tr>
        <td><b>Displacement of Participants</b><br><br>&quot;I can use AI instead of participants to perform tasks and generate data.&quot;</td>
        <td class="text-justify">The provenance of the data used in these models indicates it is not ethically sourced, falling below standards for our discipline, involving sweatshop labour and no consent for private data used in experiments. The output can contain direct original input data (i.e. double dipping), but smoothed to remove outliers, conform to our pre-existing ideas of what it should look like (data fabrication), and all-round irreplicable. Psychology is meant to study humans, not patterns at the output of biased statistical models.</td>
        </tr>
        <tr>
        <td><b>Outsourcing Programming to Companies</b><br><br>&quot;I can use AI for programming experimental paradigms and statistical analyses.&quot;</td>
        <td class="text-justify">This is an example of the field’s backsliding from adopting open science and programming skills. No formal specification will be given for code generated from a corporate-owned opaque model. The psychologist now has no reason to learn how to engineer software, and disturbingly might as well switch back to propriety software like SPSS which at least has documentation and explicit versions. Code at the output will be plagiarised, making it time-consuming to check compliance with our needs than if we wrote the code ourselves, and violating openness.</td>
        </tr>
        <tr>
        <td><b>Ghostwriter in the Machine</b><br><br>&quot;I can use AI for understanding the literature and for scholarly writing.&quot;</td>
        <td class="text-justify">This practice implicates a swathe of issues akin to automating the paper mill. First, the literature is screened by corporations, which have every reason to control the output of the model to suit their needs or minimally to ignore output issues, such as sexism. Second, the fabrication of non-existent citations which makes claims worse than baseless because they appear supported by prior work. Third, the dislocation of text from the literature since no provenance can be established, resulting in plagiarism.</td>
        </tr>
        <tr>
        <td><b>The End of Scientific Theory</b><br><br>&quot;I can outsource verbal theorising to AI or use it as a formal cognitive model.&quot;</td>
        <td class="text-justify">This not only adds to the dislocation of work from its evidential and historical basis, but also it impedes our theorising about phenomena and systems under study. In this context, we are interested in human-understandable theory and theory-based models, not statistical models which provide only a representation of the data. Scientific theories and models are only useful if we, the scientists who build and use them, understand them in deep ways and they connect transparently to research questions. AI product use is absconding scientific duty.</td>
        </tr>
        <tr>
        <td><b>Equivocation of Human-Human &amp; Human-AI</b><br><br>&quot;I can study people using chatbots as if they are socially interacting.&quot;</td>
        <td class="text-justify">Seeing client-therapist, student-teacher, patient-doctor, friendship, or romantic relationships as equivalent to those between people and artifacts is both a form of dehumanisation and a hollowing out of the target of study in social psychology: the relationship between people and other people. It is important to study the relations between humanity and machines and the social interactions mediated through technology — but to place interactions with chatbots in the same category as those between people assumes and risks too much.</td>
        </tr>
        </tbody></table>
</div></div>



<!-- <div class="row">
    <div class="col-12">
        <img class="poster is-full-width" src="{{ site.baseurl }}/images/anti-ai2.jpg" alt="icon" />
   </div>
   
   <div class="col-12">
        <img class="poster is-full-width" src="{{ site.baseurl }}/images/anti-ai1.jpg" alt="icon" />
   </div>
</div> -->

<div class="row">

    <div class="col-12 allies">

      <h2 id="allies"><a href="#allies">allies & resources</a></h2>
</div></div>

<div class="row">
    <div class="col-12 col-6-md col-6-lg">
        <p>Here are some related academics' websites (feel free to contact me to add more):</p>
        <ul>
            <li><a href="https://refusinggenai.wordpress.com/">Refusing GenAI in Writing Studies: A Quickstart Guide</a>, by Jennifer Sano-Franchini, Megan McIntyre, & Maggie Fernandes</li>

            
            <li><a href="https://against-a-i.com/">AGAINST AI</a>, by Anna Kornbluh, Krista Muratore,  & Eric Hayot</li>
        
        </ul>

   </div>

</div>

<div class="row">

    <div class="col-12  activism">

      <h2 id="activism"><a href="#activism">activism & posters</a></h2>
</div></div>

<div class="row">

  <div class="col-12 col-6-md col-6-lg">
    <!-- <a href="https://openletter.earth/open-letter-stop-the-uncritical-adoption-of-ai-technologies-in-academia-b65bba1e?limit=0"><h3>sign the Open Letter here!</h3></a> -->
             <h3 id="letter"><a href="#letter">sign the Open Letter</a></h3>

    <p>Colleagues and I have written and published: <a href="https://openletter.earth/open-letter-stop-the-uncritical-adoption-of-ai-technologies-in-academia-b65bba1e?limit=0"><i>Open Letter: Stop the Uncritical Adoption of AI Technologies in Academia</i></a>.</p>

        <p>
        Please consider adapting the letter for your employer.
    </p>
    
    
    
    </div>
    



    <div class="col-12 col-6-md col-6-lg"> 
        <h3 id="posters"><a href="#posters">have you considered not using AI?</a></h3>


        <p>I made some posters, in the style of this website, to use to attract attention to more critical thinking about AI: <b>Download them as <a href="https://doi.org/10.5281/zenodo.17112000">PDFs here</a>.</b> The QR code points to:         {% assign article = site.data.publications | where: 'doi', '10.5281/zenodo.17065099' %}
        {% include publications_copy.html publications=article %}</p>
    </div>


  

</div>

<!-- <div class="row">
    <div class="col-4">
        <img src="{{ site.baseurl }}/images/anti-ai1.png" alt="icon" class="poster is-full-width">

   </div>
   <div class="col-4">
        <img src="{{ site.baseurl }}/images/anti-ai2.png" alt="icon" class="poster is-full-width">

   </div>
   <div class="col-4">
        <img src="{{ site.baseurl }}/images/anti-ai3.png" alt="icon" class="poster is-full-width">
   </div>
</div>

<div class="row">
    <div class="col-6">
        <img src="{{ site.baseurl }}/images/anti-ai4.png" alt="icon" class="poster is-full-width">

   </div>
   <div class="col-6">
        <img src="{{ site.baseurl }}/images/anti-ai5.png" alt="icon" class="poster is-full-width">

   </div>
</div> -->




</article>
