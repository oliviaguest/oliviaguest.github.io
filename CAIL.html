---
layout: default
title: Critical AI
permalink: /ai
published: true
image: /images/cail_banner.png
css: ai
description: "On this page are some resources for Critical AI Literacy (CAIL) from my perspective."

---


<article class="page">

<div class="row">
  <div class="col-12 header">

    <h1 id="header"><a href="{{site.url}}/ai">Critical AI</a></h1>

  </div>
</div>

<div class="row">

        <div class="col-12">
        <h2 id="cail"><a href="#cail">what is critical AI literacy?</a></h2>
        </div>

    <div class="col-12 col-6-md col-6-lg">

        <h3 id="about"><a href="#about">about</a></h3>

        <p>On this page are some resources for Critical AI Literacy (CAIL) from <a href="{{site.url}}">my perspective</a>.
            Also see: <a href="https://www.ru.nl/en/research/research-projects/critical-ai-literacy-cail">the project homepage</a> and
            <a href="https://www.ru.nl/en/research/research-news/opposing-the-inevitability-of-ai-at-universities-is-possible-and-necessary">this press release</a> on our work<a href=""></a>.</p>

        <p>As we say <a href="https://www.civicsoftechnology.org/blog/no-ai-gods-no-ai-masters">here</a>,  CAIL is:
            <blockquote>an umbrella for all the prerequisite knowledge required to have an expert-level critical perspective, such as to tell apart nonsense hype from true theoretical computer scientific claims (see our <a href="https://www.ru.nl/en/research/research-projects/critical-ai-literacy-cail">project website</a>). For example, the idea that human-like systems are a sensible or possible goal is the result of circular reasoning and anthropomorphism. Such kinds of realisations are possible only when one is educated on the principles behind AI that stem from the intersection of computer and cognitive science, but cannot be learned if interference from the technology industry is unimpeded. Unarguably, rejection of this nonsense is also possible through other means, but in our context our AI students and colleagues are often already ensnared by uncritical computationalist ideology. We have the expertise to fix that, but not always the institutional support.</blockquote>
            
        </p>

        <p>CAIL also has the goal to repatriate university technological infrastructure and protect our students and selves from deskilling — as we explain <a href="https://www.ru.nl/en/research/research-news/opposing-the-inevitability-of-ai-at-universities-is-possible-and-necessary">here</a>: 
            
            <blockquote>Within just a few years, AI has turbocharged the spread of bullshit and falsehoods. It is not able to produce actual, qualitative academic work, despite the claims of some in the AI industry. As researchers, as universities, we should be clearer about pushing back against these false claims by the AI industry. We are told that AI is inevitable, that we must adapt or be left behind. But universities are not tech companies. Our role is to foster critical thinking, not to follow industry trends uncritically.</blockquote>
        See more at — and please cite — the preprint here:
        {% assign article = site.data.publications | where: 'doi', '10.5281/zenodo.17065099' %}
        {% include publications_copy.html publications=article %}</p>

            <p>Here is a wonderfully done interview by <a href="https://www.the-geyser.com/pod-interview-with-olivia-guest-and-iris-van-rooij/">Kent Anderson and Joy Moore</a>, where we got to speak at length on these topics: <a href="https://www.youtube.com/watch?v=p9w0FiHo1RU">Safeguarding Science from AI: An Interview with Olivia Guest and Iris van Rooij</a>.
            
            <!-- <div class="videoWrapper">
                <iframe width="560" height="315" src="https://www.youtube.com/embed/p9w0FiHo1RU?si=yAykif0IShwbNn8d" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
            </div> -->
        <!-- </p>

            <p> -->
                
                In general, have a look at the various resources here, such as the <a href="#blogs">blog posts</a> and <a href="#research">preprints and published papers</a> to understand our various perspectives.</p>

                        <h3 id="talks"><a href="#talks">talks & interviews</a></h3>

        {% assign talks = site.data.publications | sort:"date" | reverse | where: 'tags', 'cail' | where: 'selected', '4' %}
        {% include publications_copy.html publications=talks %}
    </div>
    <div class="col-12 col-6-md col-6-lg">


        <h3 id="blogs"><a href="#blogs">blogs & opinion pieces</a></h3>

        {% assign blogs = site.data.publications | sort:"date" | reverse | where: 'tags', 'cail'  | where: 'selected', '3' %}
        {% include publications_copy.html publications=blogs %}
        
        <h3 id="research"><a href="#research">research</a></h3>

        {% assign articles = site.data.publications | sort:"date" | reverse | where: 'tags', 'cail'  | where: 'selected', '1' %}
        {% include publications_copy.html publications=articles %}

        
    </div>

</div>


<div class="row">
    <div class="col-12">

        <h3 id="against"><a href="#against">Against the Uncritical Adoption of 'AI' Technologies in Academia</a></h3>

            <div class="is-center">
            <div class="cite is-center">
                {% assign article = site.data.publications | where:"title","Against the Uncritical Adoption of 'AI' Technologies in Academia" %}
                {% include publications_copy.html publications=article %}</div>
            </div>

           </div>

</div>

<div class="row">

        <div class="col-12 col-5-md col-5-lg">


                <div class="frame-figure bg-figure is-center">
                    <img src="{{ site.baseurl }}/images/Sets_AI.png" alt="icon" class="figure is-center">
                            <div class="extract is-center"><p>"A cartoon set theoretic view on various terms (see Table 1) used when discussing the superset AI (black outline, hatched background): LLMs are in orange; ANNs are in magenta; generative models are in blue; and finally, chatbots are in green." (<a href="https://doi.org/10.5281/zenodo.17065099">Guest et al., 2025</a>, figure 1)</p></div>
                </div>


            
        </div>

        <div class="col-12 col-7-md col-7-lg">
            <p><span class="abstract-label">Abstract:</span>
                Under the banner of progress, products have been uncritically adopted or even imposed on users — in past centuries with tobacco and combustion engines, and in the 21st with social media. For these collective blunders, we now regret our involvement or apathy as scientists, and society struggles to put the genie back in the bottle. Currently, we are similarly entangled with artificial intelligence (AI) technology. For example, software updates are rolled out seamlessly and non-consensually, Microsoft Office is bundled with chatbots, and we, our students, and our employers have had no say, as it is not considered a valid position to reject AI technologies in our teaching and research. This is why in June 2025, we co-authored an Open Letter calling on our employers to reverse and rethink their stance on uncritically adopting AI technologies. In this position piece, we expound on why universities must take their role seriously to <i>a</i>) counter the technology industry's marketing, hype, and harm; and to <i>b</i>) safeguard higher education, critical thinking, expertise, academic freedom, and scientific integrity. We include pointers to relevant work to further inform our colleagues.
                </p>

                <div class="extract is-center"><p>"Below some of the typical terminological disarray is untangled. Importantly, none of these terms
are orthogonal nor do they exclusively pick out the types of products we may wish to critique or proscribe." (<a href="https://doi.org/10.5281/zenodo.17065099">Guest et al., 2025</a>, table 1)</p></div>

                
        </div>
        

    <div class="col-12">
 
<table class="table table-bordered table-hover table-condensed">
<thead><tr><th title="Field #1" style="width: 20%">Term</th>
<th title="Field #2">Description</th>
<th title="Field #3" style="">Resources</th>
</tr></thead>
<tbody><tr>
<td>Artificial Intelligence (AI)</td>
<td>The phrase &#39;artificial intelligence&#39; was coined by McCarthy et al. (1955) in the context of proposing a summer workshop at Dartmouth College in 1956. They assumed significant progress could be made on making machines think like people. In the present, AI has no fixed meaning. It can be anything from a field of study to a piece of software.</td>
<td>Avraamidou (2024), Bender and Hanna (2025), Bloomfield (1987), Boden (2006), Brennan et al. (2025), Crawford (2021), Guest (2025), Hao (2025), McCorduck (2004), McQuillan (2022), Monett (2021), Vallor (2024), and van Rooij, Guest, et al. (2024).</td>
</tr>
<tr>
<td>Artificial neural network (ANN)</td>
<td>First proposed in McCulloch and Pitts (1943), it is a mathematical model, comprised of interconnected banks of units that perform matrix multiplication and non-linear functions. These statistical models are exposed to data (input-output pairs) that they aim to reproduce. While held to be inspired by the brain, such claims are tenuous or misleading.</td>
<td>Abraham (2002), Bishop (2021), Boden (2006), Dhaliwal et al. (2024), Guest and Martin (2023, 2025a), Hamilton (1998), Stinson (2018, 2020), and Wilson (2016).</td>
</tr>
<tr>
<td>Chatbot</td>
<td>An engineered system that appears to converse with the user using text or voice. Speech synthesis goes back hundreds of years (Dudley 1939; Gold 1990; Schroeder 1966) and Weizenbaum&#39;s (1966) ELIZA is considered the first chatbot (Dillon 2020). Modern versions can contain ANNs in addition to hardcoded rules.</td>
<td>Bates (2025), Dillon (2020), Elder (2022), Erscoi et al. (2023), Schlesinger et al. (2018), Strengers et al. (2024), Turkle (1984), and Turkle et al. (2006).</td>
</tr>
<tr>
<td>ChatGPT</td>
<td>A proprietary closed source chatbot created by OpenAI. The for-profit company OpenAI has been steeped in hype from inception. It does not provide source code for most of its models, violating open science principles for academic users. OpenAI reported $5 billion in losses in 2024 (Reuters 2025), and has received $13 billion from Microsoft (Levine 2024).</td>
<td>Andhov (2025), Birhane and Raji (2022), Dupré (2025), Gent (2024), M. T. Hicks et al. (2024), Hill  (2025), Jackson (2024), Kapoor et al. (2024), Liesenfeld, Lopez, et al. (2023), Mirowski (2023), Perrigo (2023), Titus (2024), and Widder et al. (2024).</td>
</tr>
<tr>
<td>Generative model</td>
<td>A specification on the type of statistical distribution modelled; typically contrasted with discriminative model. ANNs can be generative (e.g. Boltzmann machines) or discriminative (e.g. convolutional neural networks used for classifying images). In the context of generative AI or generative pre-trained transformer (GPT), this phrase is used inconsistently.</td>
<td>Efron (1975), Jebara (2004), Mitchell (1997), Ng and Jordan (2001), and Xue and Titterington (2008).</td>
</tr>
<tr>
<td>Large language model (LLM)</td>
<td>A model that captures some aspect of language, with the term &#39;large&#39; denoting that the number of parameters exceed a certain threshold. Modern chatbots are often LLMs, which use ANNs, along with a graphical interface so that users can input so-called text &#39;prompts.&#39; LLMs can be generative, discriminative, or neither.</td>
<td>Bender, Gebru, et al. (2021), Birhane and McGann (2024),Dentella et al. (2023, 2024), Leivada, Dentella, et al. (2024), Leivada, Günther, et al. (2024), Luitse and Denkena (2021), Shojaee et al. (2025a), Villalobos et al. (2024), and Wang et al. (2024)</td>
</tr>
</tbody></table>
</div></div>


<div class="row">
    <div class="col-12">

        <h3 id="psych"><a href="#psych">Critical Artificial Intelligence Literacy for Psychologists</a></h3>

            <div class="is-center">
            <div class="cite is-center">
                {% assign article = site.data.publications | where:"title","Critical Artificial Intelligence Literacy for Psychologists" %}
                {% include publications_copy.html publications=article %}</div>
            </div>

           </div>

</div>

<div class="row">
        <div class="col-12 col-4-md col-4-lg">
            <p><span class="abstract-label">Abstract:</span>
                Psychologists — from computational modellers to social and personality researchers to cognitive neuroscientists and from experimentalists to methodologists to theoreticians — can fall prey to exaggerated claims about artificial intelligence (AI).
                In social psychology, as in psychology generally, we see arguments taken at face value for: <i>a</i>) the displacement of experimental participants with opaque AI products;
                the outsourcing of <i>b</i>) programming, <i>c</i>) writing, and even <i>d</i>) scientific theorising to such models;
                and the notion that <i>e</i>) human-technology interactions could be on the same footing as human-human (e.g., client-therapist, student-teacher, patient-doctor, friendship, or romantic) relationships.
                But if our colleagues are, accidentally or otherwise, promoting such ideas in exchange for salary, grants, or citations, how are we as academic psychologists meant to react?
                Formal models, from statistics and computational methods broadly, have a potential obfuscatory power that is weaponisable, laying serious traps for the uncritical adopters, with even the term `AI' having murky referents.
                Herein, we concretise the term AI and counter the five related proposals 
                above — from the clearly insidious to those whose ethical neutrality is skin-deep and whose functionality is a mirage.
                Ultimately, contemporary AI is research misconduct.</p>

                <div class="extract is-center"><p>"Core reasoning issues (first column), which we name after the relevant numbered section, are characterised using a plausible quote. In the second column are responses per row; also see the named section for further reading, context, and explanations." (<a href="//doi.org/10.31234/osf.io/dkrgj_v1">Guest & van Rooij, 2025</a>, table 1)</p></div>
        </div> 
    <div class="col-12 col-8-md col-8-lg">
 
        <table class="table table-bordered table-hover table-condensed">
        <thead><tr><th title="Field #1" style="width: 25%">Uncritical Statement</th>
        <th title="Field #2">Possible Response</th>
        </tr></thead>
        <tbody><tr>
        <td><b>Lies, Damned Lies, and Statistics</b><br><br> &quot;AI products are outside my expertise but I think it is useful to deploy them.&quot;</td>
        <td class="text-justify">As a matter of fact these products are statistical models, akin to logistic regression, which all psychologists even undergraduate students are required to have a familiarity with. Additionally, it is required to know the differences between models used to perform statistical inference and those that are models of cognition. As is knowing basic open science principles. Therefore, it should come as no shock that  assuming the mantle of the non-expert here is inappropriate, and in fact may even be a form of QRP to abandon critical thinking.</td>
        </tr>
        <tr>
        <td><b>Displacement of Participants</b><br><br>&quot;I can use AI instead of participants to perform tasks and generate data.&quot;</td>
        <td class="text-justify">The provenance of the data used in these models indicates it is not ethically sourced, falling below standards for our discipline, involving sweatshop labour and no consent for private data used in experiments. The output can contain direct original input data (i.e. double dipping), but smoothed to remove outliers, conform to our pre-existing ideas of what it should look like (data fabrication), and all-round irreplicable. Psychology is meant to study humans, not patterns at the output of biased statistical models.</td>
        </tr>
        <tr>
        <td><b>Outsourcing Programming to Companies</b><br><br>&quot;I can use AI for programming experimental paradigms and statistical analyses.&quot;</td>
        <td class="text-justify">This is an example of the field’s backsliding from adopting open science and programming skills. No formal specification will be given for code generated from a corporate-owned opaque model. The psychologist now has no reason to learn how to engineer software, and disturbingly might as well switch back to propriety software like SPSS which at least has documentation and explicit versions. Code at the output will be plagiarised, making it time-consuming to check compliance with our needs than if we wrote the code ourselves, and violating openness.</td>
        </tr>
        <tr>
        <td><b>Ghostwriter in the Machine</b><br><br>&quot;I can use AI for understanding the literature and for scholarly writing.&quot;</td>
        <td class="text-justify">This practice implicates a swathe of issues akin to automating the paper mill. First, the literature is screened by corporations, which have every reason to control the output of the model to suit their needs or minimally to ignore output issues, such as sexism. Second, the fabrication of non-existent citations which makes claims worse than baseless because they appear supported by prior work. Third, the dislocation of text from the literature since no provenance can be established, resulting in plagiarism.</td>
        </tr>
        <tr>
        <td><b>The End of Scientific Theory</b><br><br>&quot;I can outsource verbal theorising to AI or use it as a formal cognitive model.&quot;</td>
        <td class="text-justify">This not only adds to the dislocation of work from its evidential and historical basis, but also it impedes our theorising about phenomena and systems under study. In this context, we are interested in human-understandable theory and theory-based models, not statistical models which provide only a representation of the data. Scientific theories and models are only useful if we, the scientists who build and use them, understand them in deep ways and they connect transparently to research questions. AI product use is absconding scientific duty.</td>
        </tr>
        <tr>
        <td><b>Equivocation of Human-Human &amp; Human-AI</b><br><br>&quot;I can study people using chatbots as if they are socially interacting.&quot;</td>
        <td class="text-justify">Seeing client-therapist, student-teacher, patient-doctor, friendship, or romantic relationships as equivalent to those between people and artifacts is both a form of dehumanisation and a hollowing out of the target of study in social psychology: the relationship between people and other people. It is important to study the relations between humanity and machines and the social interactions mediated through technology — but to place interactions with chatbots in the same category as those between people assumes and risks too much.</td>
        </tr>
        </tbody></table>
</div></div>



<!-- <div class="row">
    <div class="col-12">
        <img class="poster is-full-width" src="{{ site.baseurl }}/images/anti-ai2.jpg" alt="icon" />
   </div>
   
   <div class="col-12">
        <img class="poster is-full-width" src="{{ site.baseurl }}/images/anti-ai1.jpg" alt="icon" />
   </div>
</div> -->

<div class="row">

    <div class="col-12 allies">

      <h2 id="allies"><a href="#allies">allies & resources</a></h2>
</div></div>

<div class="row">
    <div class="col-12 col-6-md col-6-lg">
        <p>Here are some related academics' websites (feel free to contact me to add more):</p>
        <ul>
            <li><a href="https://refusinggenai.wordpress.com/">Refusing GenAI in Writing Studies: A Quickstart Guide</a>, by Jennifer Sano-Franchini, Megan McIntyre, & Maggie Fernandes</li>

            
            <li><a href="https://against-a-i.com/">AGAINST AI</a>, by Anna Kornbluh, Krista Muratore,  & Eric Hayot</li>
        
        </ul>

   </div>

</div>

<div class="row">

    <div class="col-12  activism">

      <h2 id="activism"><a href="#activism">activism & posters</a></h2>
</div></div>

<div class="row">

  <div class="col-12 col-6-md col-6-lg">
    <!-- <a href="https://openletter.earth/open-letter-stop-the-uncritical-adoption-of-ai-technologies-in-academia-b65bba1e?limit=0"><h3>sign the Open Letter here!</h3></a> -->
             <h3 id="letter"><a href="#letter">sign the Open Letter</a></h3>

    <p>Colleagues and I have written and published: <a href="https://openletter.earth/open-letter-stop-the-uncritical-adoption-of-ai-technologies-in-academia-b65bba1e?limit=0"><i>Open Letter: Stop the Uncritical Adoption of AI Technologies in Academia</i></a>.</p>

        <p>
        Please consider adapting the letter for your employer.
    </p>
    
    
    
    </div>
    



    <div class="col-12 col-6-md col-6-lg"> 
        <h3 id="posters"><a href="#posters">have you considered not using AI?</a></h3>


        <p>I made some posters, in the style of this website, to use to attract attention to more critical thinking about AI: <b>Download them as <a href="https://doi.org/10.5281/zenodo.17112000">PDFs here</a>.</b> The QR code points to:         {% assign article = site.data.publications | where: 'doi', '10.5281/zenodo.17065099' %}
        {% include publications_copy.html publications=article %}</p>
    </div>


  

</div>

<!-- <div class="row">
    <div class="col-4">
        <img src="{{ site.baseurl }}/images/anti-ai1.png" alt="icon" class="poster is-full-width">

   </div>
   <div class="col-4">
        <img src="{{ site.baseurl }}/images/anti-ai2.png" alt="icon" class="poster is-full-width">

   </div>
   <div class="col-4">
        <img src="{{ site.baseurl }}/images/anti-ai3.png" alt="icon" class="poster is-full-width">
   </div>
</div>

<div class="row">
    <div class="col-6">
        <img src="{{ site.baseurl }}/images/anti-ai4.png" alt="icon" class="poster is-full-width">

   </div>
   <div class="col-6">
        <img src="{{ site.baseurl }}/images/anti-ai5.png" alt="icon" class="poster is-full-width">

   </div>
</div> -->




</article>
