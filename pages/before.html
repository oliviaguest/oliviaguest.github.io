---
layout: default
title: We've been here before!
permalink: /before/
published: false
image: /images/before_banner.png
css: before
description: "Parallels between AI and tobacco, and other warnings."

date: 

---

<article class="page">

<div class="row">
    <div class="col-12 header" id="header">
    <div id="header-content">
    <h1 data-text="We've been here before!"><a href="{{site.url}}/before" >We've been here before!</a></h1>
    </div>
    </div>
</div>

<div class="row" id="what">


<div class="col-12 col-8-md col-8-lg ">
            <div class="container-img">
            <img src="/images/smoke.png" alt="Avatar" class="figure left image">
            <div class="overlay">
                <div class="text">Marilyn E. Jackler Memorial Collection of Tobacco Advertisements; this from <a href="https://www.si.edu/media/NMAH/NMAH-AC1224-0000083.pdf#page=4.00">1969</a>.</div>
            </div>
            </div>

</div>   

<div class="col-12 col-4-md col-4-lg vertical-center text-right">
<h2><a href="#what">What do you mean?</a></h2></div>

</div>   
<div class="row">
    <div class="col-12 col-6-md col-6-lg">
    <p>We have certainly been here before. Many many times in the past, companies — just like AI companies now — have lied to us to sell us products. Not only is there no reason to assume the AI industry is different, there is in fact much to make us think they are <i>knowingly</i> misleading us. To understand this, take a look at this great work called <a href="https://www.eea.europa.eu/en/analysis/publications/late-lessons-2"><i>Late lessons from early warnings: science, precaution, innovation</i></a> by the European Environment Agency (EEA): </p>

    <blockquote>The 2013 Late lessons from early warnings report is the second of its type produced by the European Environment Agency (EEA) in collaboration with a broad range of external authors and peer reviewers. The case studies across both volumes of Late lessons from early warnings cover a diverse range of chemical and technological innovations, and highlight a number of systemic problems. The 'Late Lessons Project' illustrates how damaging and costly the misuse or neglect of the precautionary principle can be, using case studies and a synthesis of the lessons to be learned and applied to maximising innovations whilst minimising harms.</blockquote>   

    <p>Also there are well-known patterns of our thinking that are affected by interacting with certain machines. As <a href="https://www.taylorfrancis.com/chapters/edit/10.4324/9780429505331-2/culture-artificial-intelligence-brian-bloomfield">Brian P. Bloomfield (1987, p. 72)</a> explains four decades ago:</p>

    <blockquote>While opacity is a distinguishing feature of many other areas of science and technology, the myths surrounding computing may stem less from the fact that it is an opaque esoteric subject and more from the way in which it can be seen to blur the boundary between people and machines (Turkle 1984). To be sure, most people do not understand the workings of a television set or how to program their video cassette recorders properly, but then they do not usually believe that these machines can have intelligence. The public myths about computing and AI are also no doubt due to the ways in which computers are often depicted in the mass media — e.g. as an abstract source of wisdom, or as a mechanical brain.</blockquote>
    
    <p>For detailed analysis and more examples see:    </p>
        {% assign article = site.data.publications | where:"title","Against the Uncritical Adoption of 'AI' Technologies in Academia" %}
        {% include publications.html publications=article %}

    <p>Another related aspect — described by <a href="https://web.mit.edu/slava/space/essays/essay-ponomareva.htm">Valentina Ponomareva (1998)</a>, is that:
        <blockquote>
            it is impossible to create an absolutely reliable automatic system, and sooner or later people face the necessity to act after equipment fails. [...] If the cosmonaut loses such skills because of [their] passive role [due to being typically limited to monitoring and observation only], the probability of [their] choosing and carrying out the right procedure in an emergency would be small. This contradiction is inherent in automatic control systems. 
        </blockquote>

    For more on this angle of AI see:    </p>

        <div class="is-center">
        <div class="cite is-center">
        {% assign article = site.data.publications | where:"title","What Does 'Human-Centred AI' Mean?" %}
        {% include publications.html publications=article %}</div>
        </div>
</div>  

</div>

<div class="row right-row" id="how">
    <div class="col-12 col-7-md col-7-lg vertical-center">
    <h2 class="text-left"><a href="#how">How is this possible?</a></h2></div>

<div class="col-12 col-5-md col-5-lg  vertical-center">
    <!-- <div class=" is-right">
        <img src="/images/dorothy.png" id="" class="figure right">
    </div> -->

    <div class="container-img">
    <img src="/images/dorothy.png" alt="Avatar" class="figure right image">
    <div class="overlay">
    <div class="text"><a href="https://pdimagearchive.org/images/9cfe5e01-4cf6-4fc8-9e48-aa0570ad2e11/">"She Caught Toto by the Ear."</a> by W. W. Denslow, 1900.</div>
    </div>
    </div>

</div>  



</div>

<div class="row">

    <div class="col-12 col-6-md col-6-lg"></div>
    <div class="col-12 col-6-md col-6-lg">
        <p>Our present predicament is enabled by the fact that regulation is apparently not only missing in the case of AI, but also <i>very</i> hard to enforce even for industries where there is complete mainstream acceptance of their malevolent goals and harmful practices.
            The tobacco industry for example, still publishes research even in journals which try to enforce complete bans on such work. For one, they run disinformation campaigns, as <a href="https://ajph.aphapublications.org/doi/abs/10.2105/AJPH.2004.050963">Annamaria Baba and colleagues (2011)</a> explain:</p>
            <blockquote>Internal tobacco industry documents that have been made available through litigation give us the opportunity to analyze one industry’s involvement in a broader industry strategy to secure enactment of the data access and data quality provisions. These documents provide unprecedented insight into the industry’s motives, strategies, and tactics to challenge the scientific basis for public health policies. In the 1990s Philip Morris implemented a 10-year “sound science” public relations campaign to create controversy regarding evidence that environmental toxins cause disease. Our article describes the tobacco industry’s later campaign to advance the “sound science” concept via legislation.</blockquote>
            <p>For another, as mentioned the tobacco industry continues to indirectly or directly publish medical research, as <a href="https://doi.org/10.1136/bmj.q1153">Irene van den Berg and coauthors (2024)</a> document:
                </p>
            <blockquote>In recent years the “big four” global tobacco companies (according to sales1)—Philip Morris International (PMI)/Altria, British American Tobacco (BAT), Imperial Brands, and Japan Tobacco International (JTI)—have invested billions in companies that produce medicines or other medical products. These investments include treatments for conditions caused or aggravated by smoking. For example, Vectura, a subsidiary of PMI since 2021, produces an inhaler used by patients with chronic obstructive pulmonary disease or asthma. And JTI’s pharmaceutical branch produces treatments for lung cancer, skin conditions such as psoriasis and atopic dermatitis, and heart disease.</blockquote>
            <p>The same tactics are also used by petrochemical industry to sabotage science and regulation. If you want to read more on that read <a href="https://doi.org/10.5281/zenodo.15274865">Linda Knoester and colleagues (2025)</a>: <i>Academic Collaborations and Public Health: Lessons from Dutch Universities' Tobacco Industry Partnerships for Fossil Fuel Ties</i>.</p>
                
            <p>The AI and generally the technology industry is no different. Why should they be? They fund researchers and institutes, therefore creating academics and publications with conflicting interests, which often go un- or under-acknowledged especially in mainstream coverage. These conflicts of interest are sometimes very time consuming to dig up, for example see: <a href="https://theluddite.org/post/replika.html"><i>Nature's Folly: A Response to Nature's "Loneliness and suicide mitigation for students using GPT3-enabled chatbots"</i></a>.</p>

            <p>Standing against these corrosive forces is important, especially since they converge. For example, the AI industry wastefully burns fossil fuels while pretending to want to combat climate crisis. Read more here:</p>


                {% assign article = site.data.publications | where:"title","Critical AI Literacy: Beyond hegemonic perspectives on sustainability" %}
                {% include publications.html publications=article %}

                {% assign article = site.data.publications | where:"title","Against the Uncritical Adoption of 'AI' Technologies in Academia" %}
                {% include publications.html publications=article %}
                </div>
            
    </div>

</div>


<div class="row" id="spot" >




    <div class="col-12 col-5-md col-5-lg vertical-center">
    <div class=" is-left">
            <img src="/images/electricity.png" id="" class="figure left">
            <!-- https://med.stanford.edu/news/insights/2019/04/doctors-smoking-new-exhibit-displays-now-startling-ads.html -->
        </div>

    </div>  


    <div class="col-12 col-7-md col-7-lg vertical-center">
    <h2 class="text-right"><a href="#spot">How can we spot it?</a></h2></div>
</div>

                <div class="row">
    <div class="col-12 col-7-md col-7-lg">
        <p><span class="abstract-label">Abstract:</span>
        Critical Artificial Intelligence Literacies (CAILs) is the collection of ways of thinking about and relating to so-called artificial intelligence (AI) that rejects dominant frames presented by the technology industry, by naive computationalism, and by dehumanising ideologies. Instead, CAILs centre human cognition and uphold the integrity of academic research and education. We present a selection of CAILs across research and education, which we analyse into the following non-orthogonal dimensions: <i>conceptual clarity, critical thinking, decoloniality, respecting expertise,</i> and <i>slow science</i>. Finally, we note how we see the present with and without a wider adoption of CAILs — a fundamental aspect is the assertion that AI cannot be allowed to drive change, even positive change, in education or research. Instead cultivation of and adherence to shared values and goals must guide us. Ultimately, CAILs minimally ask us to contemplate how we as academics can stop AI companies from wielding so much power.
        </p>
        <div class="extract is-center"><p>"The important dimensions of CAILs across research and education; clockwise from 12 o’clock: <i>Conceptual Clarity</i> is the idea that terms should refer. <i>Critical Thinking</i> is deep engagement with the relationships between statements about the world. <i>Decoloniality</i> is the process of de-centring and addressing dominant harmful views and practices. <i>Respecting Expertise</i> is the epistemic compact between professionals and society. <i>Slow Science</i> is a disposition towards preferring psychologically, techno-socially, and epistemically healthy practices. The lines between dimensions represent how they are interwoven both directly and indirectly." (<a href="//doi.org/10.5281/zenodo.17786243">Guest et al., 2025</a>, figure 1)</p></div>
    </div> 
    <div class="col-12 col-5-md col-5-lg vertical-center">
        <img src="{{ site.baseurl }}/images/CAILs_figure.png" alt="icon" class="figure is-center" id="cails">
    </div>
</div>

<div class="row">

    <div class="col-12 col-6-md col-6-lg">
        <p>If you want to help yourself and others, even just perusing websites and papers such as these on <a href="/ai">critical artificial intelligence literacy</a> is more than enough for a first step. But practically if you're interested in actively disentangling, you can consider thinking deeply about some aspects of CAILs we outline here:</p>

                {% assign article = site.data.publications | where:"title","Towards Critical Artificial Intelligence Literacies" %}
                {% include publications.html publications=article %}
                
            <div class="figure" id="cails">{% include cails_figure.html %}
            </div>



    </div>
    <div class="col-12 col-6-md col-6-lg">
    </div>

</div>


<div class="row right-row" id="can">

  <div class="col-12 col-4-md col-4-lg vertical-center">
<h2 class="text-left"><a href="#can">What can we do?</a></h2></div>


<div class="col-12 col-8-md col-8-lg vertical-center">
    <div class=" is-right">
            <img src="/images/eclipse.png" id="" class="figure right">
        </div>
</div>  


  
</div>


<div class="row">


    <div class="col-12 col-6-md col-6-lg vertical-center">

    </div>  

    </div>



<div class="row">
<!-- <div class="col-12 col-4-md col-4-lg vertical-center">
<h2><a href="#what">What do you mean?</a></h2></div> -->

<div class="col-12 col-12-md col-12-lg  vertical-center">
    <div class=" is-center">
            <img src="/images/metamorphosis.png" id="" class="figure right">
        </div>

</div>   
</div>   


</article>